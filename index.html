<!-- Head. Used to add imports, set a lot of 'metatags' and to signal the start of the page. If we want to work with Cookies and other session storage objects, we must put them before the head. -->
<head> 
    <!-- Importing CSS files -->
    <link href="python/html/externalCSS/bootstrap.min.css" rel="stylesheet">
	<link href="python/html/externalCSS/bootstrap-material-design.min.css" rel="stylesheet">
    <link href="python/html/xternalCSS/ripples.min.css" rel="stylesheet">
    <link href="python/html/externalCSS/material-theme.css" rel="stylesheet">
		<!-- Importing JS files -->
	<script src="python/html/externalJS/jquery-1.11.2.min.js"></script>
	<script src="python/html/externalJS/bootstrap.min.js"></script>
	<script src="python/html/externalJS/material.min.js"></script>
	<script src="python/html/externalJS/ripples.min.js"></script>

	<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<!-- Adding script tags for Jquery init of dropdown and material bootstrap -->
 <script>
     $(document).ready(function(){
		$.material.init();
    });
</script>

<nav class="navbar navbar-material-red navbar-static-top " role="navigation">
	<div class = "container">
		<!-- Drop down button for small screens -->
		<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
        </button>
		<!-- Left justified logo/text -->
		<div class="navbar-header">
			<a class="navbar-brand" href="index.php">
				Toasted Smores 
			</a>
		</div>
		<!-- What goes under the drop down button/rest of navbar -->
		<div class="collapse navbar-collapse">
			<ul class="nav navbar-nav navbar-left">
				<li><a href="python/html/index.html">User Interface</a></li>
			</ul>
		</div>
	</div>
</nav>
	
<body>
	<div class="container rowisEnabledButton-offcanvas row-offcanvas-left">
		<div class="well column  col-lg-12  col-sm-12 col-xs-12" id="content">
			<h1>Helping Hand - General Purpose Kitchen Aide</h1>
			<div class="embed-responsive embed-responsive-16by9">
				<iframe width="1280" height="720" src="https://www.youtube.com/embed/b4DWCtLnGag" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>			</div>	
			<div id = "vision" class = "row">
				<h2>Vision</h2>
				<div class="col-lg-6">
					<div class = "row">
						<h3>Description</h3>
						The vision aspect of the project was implemented by using Python with OpenCV. 
						Image classification was accomplished by using a pretrained machine learning model called MobileNet. 
						The MobileNet model leveraged the ideal balance between accuracy and performance. 
						Once the vision module identified an bottle object classification, it would perform a search around the surrounding 
						bounding box in order to search for a QR code. It would search for a QR code to determine what kind of bottle it was.
					</div>
					<br>
					<div class = "row">
						<h3>Workflow</h3>
						<ol type="1">
							<li> Detect and Classify Objects </Object></li>
							<li> Find the Position for a Bottle </li>
							<li> Read the QR Code on the Bottle </li>
							<li> Determine the Contents of the Bottle </li>
						</ol>
					</div>
				</div>
				<div class="col-lg-6">
					<img src="images/bottleClassification.png"  class="img-responsive img-rounded" alt="Bottle Classification">
					<h4>Sample training detection</h4>
				</div>
			</div>
		
		
		
			<div id = "ui" class = "row">
				<h2>User Interface</h2>
				<div class="col-lg-6">
					<div class = "row">
						<h3>Description</h3>
						This user interface was designed to help us test the robot as well as provide a user friendly experience.
						To do this, we split up communication to and from the interface into two sections: data and commands.
						Data dealt with updating the user. These packets could be in the form of a JSON payload with robot states or the location of all identified items.
						Command packets are generated by the interface to make an action be triggered. This includes scanning or launching a sequence. 
						<br><br>
						This entire UI was made in a pure HTML and JavaScript front end and Python back end, written from scratch.
						We kept the back end in pure Python 3 because the rest of the vision software and robot control software was written in Python. 
						This allowed us to facilitate the merging of different parts and allowed the entire system to communicate properly.
						
					</div>
				</div>
				<div class="col-lg-6">
					<img src="images/control_panel.png"  class="img-responsive img-rounded" alt="User Interface">
					<h4>Control Panel With Test Ingredients</h4>
				</div>
			</div>
			
			<div id = "roboticSystem" class = "row">
				<h2>Robot</h2>
				<div class="col-lg-6">
					<div class = "row">
						<h3>Description</h3>
						Building the robot was one of the most difficult parts of the project. 
						We went through many different iterations, trying to optimize cost and power. 
						In the end, we went with using one brushed DC motor to control the rotational base, 
						along with 3 other servos to control tilt, the claw, and the extension arm.
						An interesting feature about the robot is that the arm is a 4 - bar linkage. 
						The linkage consists of parallel bars that allow the claw to be parallel to the base 
						at any orientation.
					</div>
				</div>
				<div class="col-lg-6">
					<img src="images/robot.jpg"  class="img-responsive img-rounded" alt="Robot">
					<h4>Robot</h4>
				</div>
				<div class="col-lg-4">
					<img src="images/printing.jpg"  class="img-responsive img-rounded" alt="3D Printing">
					<h4>3D Printing Wrist Base</h4>
				</div>
				<div class="col-lg-4">
					<img src="images/originalArm.jpg"  class="img-responsive img-rounded" alt="Original Design">
					<h4>Linkage From Original Design</h4>
				</div>
				<div class="col-lg-4">
					<img src="images/conceptSketch.jpg"  class="img-responsive img-rounded" alt="Concept Sketches">
					<h4>Linkage Concept Sketches</h4>
				</div>
			</div>
			
			<div id = "control" class = "row">
				<h2>Control System</h2>
				<div class="col-lg-12">
					<div class = "row">
						<h3>Description</h3>
						Designing a control system to allow our robot to reliable and precisely execute our movements was a big challenge. 
						Our base is a closed loop control system, we set what angle we want to go through and a PID loop
						becomes active to correct course and position and will fight external stimuli to preserve position. 
						<br>
						<br>
						An additional problem we faced was how we were going to have the arm find objects in the environment.
						For the sake of this project, we determined that pre-scanning the environment would be the most efficient. 
						At each angle we went to, we would generate a consensus of what we were seeing by repeatedly sampling and using the
						machine learning image classifier to tell us what it thought we saw. After this, for any item we saw in the world,
						we performed a calculation to find what angle would lead us closest to the center of mass of the object. We would 
						find how the center of each object was from the center of the frame at each angle, then find what minor adjustments we 
						had to perform to get to the center. This ended up working well. 
					</div>
				</div>
			</div>
		</div>
	</div>
</body>
